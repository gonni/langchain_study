{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH01-Basic\n"
     ]
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()\n",
    "\n",
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH01-Basic\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 입력하고 그 데이터를 분석하여 패턴을 찾아내는 과정입니다. 모델은 입력된 데이터를 기반으로 가중치와 편향을 조절하면서 학습을 진행하고, 이를 통해 입력된 데이터에 대한 패턴을 학습하게 됩니다.\n",
      "\n",
      "모델은 입력된 데이터로부터 패턴을 찾아내기 위해 다양한 수학적인 연산을 수행하고, 이를 통해 입력된 데이터와 실제 결과 사이의 관계를 모델링합니다. 학습 과정에서 모델은 손실 함수를 통해 예측값과 실제값의 차이를 계산하고, 이를 최소화하기 위해 가중치와 편향을 업데이트합니다.\n",
      "\n",
      "이러한 반복적인 과정을 통해 모델은 학습 데이터에 대한 패턴을 학습하고, 이를 토대로 새로운 데이터에 대한 예측을 수행할 수 있습니다. 이렇게 학습된 모델은 실제 데이터를 기반으로 입력된 데이터에 대한 예측을 수행하며, 인공지능 기술을 구현하는 데 활용됩니다."
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_response  # 스트리밍 출력\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# template 정의\n",
    "# template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# # from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "# prompt_template = PromptTemplate.from_template(template)\n",
    "# prompt_template\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "# input 딕셔너리에 주제를 '인공지능 모델의 학습 원리'으로 설정합니다.\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "\n",
    "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\n",
    "# chain.invoke(input)\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 회화:\n",
      "- Hello! I’d like to order a large pepperoni pizza with extra cheese, please.\n",
      "- Sure, anything else to add?\n",
      "- Yes, can I also have a 2-liter bottle of Coke and an order of garlic bread?\n",
      "- Absolutely. Will that be for delivery or pickup?\n",
      "- Delivery, please. It’s for 742 Evergreen Terrace.\n",
      "- Great. Your total comes to $28.50. It should be there in about 30-40 minutes.\n",
      "- Perfect, thank you!\n",
      "\n",
      "한글 해석:\n",
      "- 안녕하세요! 대형 페페로니 피자에 치즈를 추가해서 주문하고 싶어요.\n",
      "- 네, 추가로 더 주문하실 건가요?\n",
      "- 네, 콜라 2리터와 마늘 빵 하나도 주문할게요.\n",
      "- 알겠습니다. 배달로 할까요 아니면 직접 가지러 오실 건가요?\n",
      "- 배달로 부탁드립니다. 742 에버그린 테라스로요.\n",
      "- 좋습니다. 총 금액은 $28.50이고, 대략 30-40분 내에 도착할 겁니다.\n",
      "- 완벽해요, 감사합니다!"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해 주세요.\n",
    "\n",
    "상황:\n",
    "{question}\n",
    "\n",
    "FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿을 이용하여 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI 챗모델을 초기화합니다.\n",
    "model = ChatOpenAI(model_name=\"gpt-4-turbo\")\n",
    "\n",
    "# 문자열 출력 파서를 초기화합니다.\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "# answer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})\n",
    "# # 스트리밍 출력\n",
    "# stream_response(answer)\n",
    "\n",
    "# 이번에는 question 을 '미국에서 피자 주문'으로 설정하여 실행합니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"미국에서 피자 주문\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
